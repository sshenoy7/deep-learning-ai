{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lamini\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "lamini.api_url = os.getenv(\"POWERML__PRODUCTION__URL\")\n",
    "lamini.api_key = os.getenv(\"POWERML__PRODUCTION__KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "from utilities import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from llama import BasicModelRunner\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"lamini_docs.jsonl\"\n",
    "dataset_path = f\"/content/{dataset_name}\"\n",
    "use_hf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"lamini/lamini_docs\"\n",
    "use_hf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/pythia-70m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": use_hf,\n",
    "        \"path\": dataset_path\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-03-07 15:21:55,634 - DEBUG - utilities - Config: datasets.path: lamini/lamini_docs\n",
      "datasets.use_hf: true\n",
      "model.max_length: 2048\n",
      "model.pretrained_name: EleutherAI/pythia-70m\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize True lamini/lamini_docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 15:22:02,122 - DEBUG - fsspec.local - open file: /Users/shenoy/.cache/huggingface/datasets/lamini___lamini_docs/default/0.0.0/05bd680b81d69a7a1d38193873f1487d73e535bf/dataset_info.json\n",
      "2024-03-07 15:22:02,174 - DEBUG - fsspec.local - open file: /Users/shenoy/.cache/huggingface/datasets/lamini___lamini_docs/default/0.0.0/05bd680b81d69a7a1d38193873f1487d73e535bf/dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1260\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 140\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"lamini_docs_200_steps/final_2\", local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 15:28:17,109 - DEBUG - __main__ - Select GPU device\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    logger.debug(\"Select GPU device\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    logger.debug(\"Select CPU device\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    max_length=max_output_tokens\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): Can Lamini generate technical documentation or user manuals for software projects?\n",
      "Correct answer from Lamini docs: Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.\n",
      "Model's answer: \n",
      "Yes, Lamini can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate\n"
     ]
    }
   ],
   "source": [
    "test_text = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from Lamini docs: {test_dataset[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference(test_text, base_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
    "output_dir = trained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=3e-4,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=3,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 512)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
      ")\n",
      "Memory footprint 0.3084454 GB\n",
      "Flops 2195.667812352 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_flops = (\n",
    "  base_model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, training_config[\"model\"][\"max_length\"])\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(base_model)\n",
    "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 01:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.430434</td>\n",
       "      <td>4.311737</td>\n",
       "      <td>47.199072</td>\n",
       "      <td>3721544075934.758301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 15:28:47,084 - DEBUG - utilities - Step (1) Logs: {'loss': 1.7705, 'grad_norm': 42.441287994384766, 'learning_rate': 0.0003, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
      "2024-03-07 15:28:47,668 - DEBUG - utilities - Step (2) Logs: {'loss': 1.7803, 'grad_norm': 40.761634826660156, 'learning_rate': 0.00029849246231155777, 'epoch': 0.01, 'iter_time': 0.5845279693603516, 'flops': 3756309240009.0234, 'remaining_time': 115.73653793334961}\n",
      "2024-03-07 15:28:48,245 - DEBUG - utilities - Step (3) Logs: {'loss': 9.2781, 'grad_norm': 119.2063217163086, 'learning_rate': 0.0002969849246231155, 'epoch': 0.01, 'iter_time': 0.5804829597473145, 'flops': 3782484525140.547, 'remaining_time': 114.35514307022095}\n",
      "2024-03-07 15:28:48,754 - DEBUG - utilities - Step (4) Logs: {'loss': 8.1823, 'grad_norm': 197.8565216064453, 'learning_rate': 0.00029547738693467337, 'epoch': 0.01, 'iter_time': 0.5565606753031412, 'flops': 3945064590048.674, 'remaining_time': 109.08589235941568}\n",
      "2024-03-07 15:28:49,335 - DEBUG - utilities - Step (5) Logs: {'loss': 6.1447, 'grad_norm': 96.8192138671875, 'learning_rate': 0.00029396984924623116, 'epoch': 0.02, 'iter_time': 0.5628265142440796, 'flops': 3901144947481.65, 'remaining_time': 109.75117027759552}\n",
      "2024-03-07 15:28:49,873 - DEBUG - utilities - Step (6) Logs: {'loss': 10.1959, 'grad_norm': 334.09893798828125, 'learning_rate': 0.0002924623115577889, 'epoch': 0.02, 'iter_time': 0.5578214168548584, 'flops': 3936148283319.317, 'remaining_time': 108.21735486984254}\n",
      "2024-03-07 15:28:50,405 - DEBUG - utilities - Step (7) Logs: {'loss': 7.0012, 'grad_norm': 113.44781494140625, 'learning_rate': 0.0002909547738693467, 'epoch': 0.02, 'iter_time': 0.5535539786020914, 'flops': 3966492694889.113, 'remaining_time': 106.83591787020364}\n",
      "2024-03-07 15:28:50,973 - DEBUG - utilities - Step (8) Logs: {'loss': 8.1406, 'grad_norm': 119.88177490234375, 'learning_rate': 0.0002894472361809045, 'epoch': 0.03, 'iter_time': 0.5556447165352958, 'flops': 3951567876039.5923, 'remaining_time': 106.68378557477679}\n",
      "2024-03-07 15:28:51,533 - DEBUG - utilities - Step (9) Logs: {'loss': 7.6978, 'grad_norm': 146.483154296875, 'learning_rate': 0.0002879396984924623, 'epoch': 0.03, 'iter_time': 0.556089848279953, 'flops': 3948404775133.8057, 'remaining_time': 106.21316102147102}\n",
      "2024-03-07 15:28:52,086 - DEBUG - utilities - Step (10) Logs: {'loss': 6.488, 'grad_norm': 98.16059875488281, 'learning_rate': 0.0002864321608040201, 'epoch': 0.03, 'iter_time': 0.5558337635464139, 'flops': 3950223891299.57, 'remaining_time': 105.60841507381863}\n",
      "2024-03-07 15:28:52,700 - DEBUG - utilities - Step (11) Logs: {'loss': 7.5178, 'grad_norm': 98.34268951416016, 'learning_rate': 0.0002849246231155779, 'epoch': 0.03, 'iter_time': 0.5616075038909912, 'flops': 3909612669239.1597, 'remaining_time': 106.14381823539735}\n",
      "2024-03-07 15:28:53,246 - DEBUG - utilities - Step (12) Logs: {'loss': 7.4141, 'grad_norm': 98.71003723144531, 'learning_rate': 0.00028341708542713564, 'epoch': 0.04, 'iter_time': 0.560189810666171, 'flops': 3919506871681.4717, 'remaining_time': 105.31568440524015}\n",
      "2024-03-07 15:28:53,768 - DEBUG - utilities - Step (13) Logs: {'loss': 8.7966, 'grad_norm': 139.35809326171875, 'learning_rate': 0.00028190954773869343, 'epoch': 0.04, 'iter_time': 0.5570294062296549, 'flops': 3941744884195.1426, 'remaining_time': 104.16449896494547}\n",
      "2024-03-07 15:28:54,371 - DEBUG - utilities - Step (14) Logs: {'loss': 6.9786, 'grad_norm': 160.7906036376953, 'learning_rate': 0.00028040201005025123, 'epoch': 0.04, 'iter_time': 0.560585462130033, 'flops': 3916740551938.706, 'remaining_time': 104.26889595618614}\n",
      "2024-03-07 15:28:54,900 - DEBUG - utilities - Step (15) Logs: {'loss': 7.8003, 'grad_norm': 157.76278686523438, 'learning_rate': 0.000278894472361809, 'epoch': 0.05, 'iter_time': 0.5582952158791679, 'flops': 3932807858463.1997, 'remaining_time': 103.28461493764605}\n",
      "2024-03-07 15:28:55,473 - DEBUG - utilities - Step (16) Logs: {'loss': 6.9017, 'grad_norm': 140.7388153076172, 'learning_rate': 0.0002773869346733668, 'epoch': 0.05, 'iter_time': 0.5593095302581788, 'flops': 3925675665384.1997, 'remaining_time': 102.91295356750489}\n",
      "2024-03-07 15:28:56,054 - DEBUG - utilities - Step (17) Logs: {'loss': 6.5928, 'grad_norm': 113.32047271728516, 'learning_rate': 0.0002758793969849246, 'epoch': 0.05, 'iter_time': 0.5606294274330139, 'flops': 3916433395951.8145, 'remaining_time': 102.59518522024155}\n",
      "2024-03-07 15:28:56,582 - DEBUG - utilities - Step (18) Logs: {'loss': 7.2646, 'grad_norm': 123.3468017578125, 'learning_rate': 0.00027437185929648236, 'epoch': 0.06, 'iter_time': 0.5587048811071059, 'flops': 3929924163184.6094, 'remaining_time': 101.68428836149327}\n",
      "2024-03-07 15:28:57,160 - DEBUG - utilities - Step (19) Logs: {'loss': 6.8463, 'grad_norm': 76.61421966552734, 'learning_rate': 0.0002728643216080402, 'epoch': 0.06, 'iter_time': 0.5597811142603556, 'flops': 3922368505148.942, 'remaining_time': 101.32038168112436}\n",
      "2024-03-07 15:28:57,710 - DEBUG - utilities - Step (20) Logs: {'loss': 6.9188, 'grad_norm': 87.64645385742188, 'learning_rate': 0.00027135678391959796, 'epoch': 0.06, 'iter_time': 0.5592745730751439, 'flops': 3925921037817.306, 'remaining_time': 100.66942315352591}\n",
      "2024-03-07 15:28:58,295 - DEBUG - utilities - Step (21) Logs: {'loss': 9.1157, 'grad_norm': 158.97796630859375, 'learning_rate': 0.00026984924623115576, 'epoch': 0.07, 'iter_time': 0.5605668544769287, 'flops': 3916870565600.6055, 'remaining_time': 100.34146695137024}\n",
      "2024-03-07 15:28:58,890 - DEBUG - utilities - Step (22) Logs: {'loss': 7.0708, 'grad_norm': 77.06304931640625, 'learning_rate': 0.00026834170854271355, 'epoch': 0.07, 'iter_time': 0.5622141020638602, 'flops': 3905394411651.739, 'remaining_time': 100.07411016736712}\n",
      "2024-03-07 15:28:59,445 - DEBUG - utilities - Step (23) Logs: {'loss': 6.3868, 'grad_norm': 105.5147476196289, 'learning_rate': 0.0002668341708542713, 'epoch': 0.07, 'iter_time': 0.5618574944409457, 'flops': 3907873142346.732, 'remaining_time': 99.44877651604739}\n",
      "2024-03-07 15:28:59,999 - DEBUG - utilities - Step (24) Logs: {'loss': 6.4603, 'grad_norm': 99.6583251953125, 'learning_rate': 0.00026532663316582915, 'epoch': 0.08, 'iter_time': 0.5615443872368854, 'flops': 3910052103193.342, 'remaining_time': 98.83181215369183}\n",
      "2024-03-07 15:29:00,539 - DEBUG - utilities - Step (25) Logs: {'loss': 6.2838, 'grad_norm': 96.42878723144531, 'learning_rate': 0.00026381909547738695, 'epoch': 0.08, 'iter_time': 0.5606249471505483, 'flops': 3916464694466.0186, 'remaining_time': 98.10936575134596}\n",
      "2024-03-07 15:29:01,106 - DEBUG - utilities - Step (26) Logs: {'loss': 6.3294, 'grad_norm': 70.24512481689453, 'learning_rate': 0.0002623115577889447, 'epoch': 0.08, 'iter_time': 0.560869083404541, 'flops': 3914759927618.116, 'remaining_time': 97.59122051239014}\n",
      "2024-03-07 15:29:01,633 - DEBUG - utilities - Step (27) Logs: {'loss': 6.7058, 'grad_norm': 96.81639862060547, 'learning_rate': 0.0002608040201005025, 'epoch': 0.09, 'iter_time': 0.5595889549988967, 'flops': 3923715421360.182, 'remaining_time': 96.80888921480913}\n",
      "2024-03-07 15:29:02,215 - DEBUG - utilities - Step (28) Logs: {'loss': 7.0674, 'grad_norm': 101.42826843261719, 'learning_rate': 0.0002592964824120603, 'epoch': 0.09, 'iter_time': 0.560401404345477, 'flops': 3918026963041.677, 'remaining_time': 96.38904154742205}\n",
      "2024-03-07 15:29:02,760 - DEBUG - utilities - Step (29) Logs: {'loss': 7.181, 'grad_norm': 87.08370971679688, 'learning_rate': 0.000257788944723618, 'epoch': 0.09, 'iter_time': 0.5598476699420384, 'flops': 3921902207040.211, 'remaining_time': 95.73395156008857}\n",
      "2024-03-07 15:29:03,265 - DEBUG - utilities - Step (30) Logs: {'loss': 5.3898, 'grad_norm': 63.49886703491211, 'learning_rate': 0.0002562814070351759, 'epoch': 0.1, 'iter_time': 0.5579650319855789, 'flops': 3935135154506.867, 'remaining_time': 94.85405543754841}\n",
      "2024-03-07 15:29:03,836 - DEBUG - utilities - Step (31) Logs: {'loss': 6.6662, 'grad_norm': 94.19824981689453, 'learning_rate': 0.0002547738693467337, 'epoch': 0.1, 'iter_time': 0.5584100643793742, 'flops': 3931998995742.1343, 'remaining_time': 94.37130088011425}\n",
      "2024-03-07 15:29:04,404 - DEBUG - utilities - Step (32) Logs: {'loss': 5.071, 'grad_norm': 67.57710266113281, 'learning_rate': 0.0002532663316582914, 'epoch': 0.1, 'iter_time': 0.5587304792096538, 'flops': 3929744114654.0967, 'remaining_time': 93.86672050722184}\n",
      "2024-03-07 15:29:04,987 - DEBUG - utilities - Step (33) Logs: {'loss': 7.1881, 'grad_norm': 98.6351318359375, 'learning_rate': 0.0002517587939698492, 'epoch': 0.1, 'iter_time': 0.5594595298171043, 'flops': 3924623132382.42, 'remaining_time': 93.42974147945642}\n",
      "2024-03-07 15:29:05,521 - DEBUG - utilities - Step (34) Logs: {'loss': 6.5354, 'grad_norm': 115.08985900878906, 'learning_rate': 0.000250251256281407, 'epoch': 0.11, 'iter_time': 0.5587001497095282, 'flops': 3929957444066.449, 'remaining_time': 92.74422485178168}\n",
      "2024-03-07 15:29:06,078 - DEBUG - utilities - Step (35) Logs: {'loss': 7.0946, 'grad_norm': 108.09113311767578, 'learning_rate': 0.0002487437185929648, 'epoch': 0.11, 'iter_time': 0.5586457322625553, 'flops': 3930340259576.293, 'remaining_time': 92.17654582332163}\n",
      "2024-03-07 15:29:06,633 - DEBUG - utilities - Step (36) Logs: {'loss': 7.0181, 'grad_norm': 73.57320404052734, 'learning_rate': 0.0002472361809045226, 'epoch': 0.11, 'iter_time': 0.5585551943097796, 'flops': 3930977340682.0444, 'remaining_time': 91.60305186680385}\n",
      "2024-03-07 15:29:07,198 - DEBUG - utilities - Step (37) Logs: {'loss': 4.9192, 'grad_norm': 85.33812713623047, 'learning_rate': 0.0002457286432160804, 'epoch': 0.12, 'iter_time': 0.5587334103054471, 'flops': 3929723499354.8667, 'remaining_time': 91.07354587978787}\n",
      "2024-03-07 15:29:07,758 - DEBUG - utilities - Step (38) Logs: {'loss': 5.8571, 'grad_norm': 96.13142395019531, 'learning_rate': 0.00024422110552763815, 'epoch': 0.12, 'iter_time': 0.5587474011086129, 'flops': 3929625100708.4185, 'remaining_time': 90.51707897959528}\n",
      "2024-03-07 15:29:08,276 - DEBUG - utilities - Step (39) Logs: {'loss': 6.9256, 'grad_norm': 90.47091674804688, 'learning_rate': 0.00024271356783919594, 'epoch': 0.12, 'iter_time': 0.5576871821754857, 'flops': 3937095709797.21, 'remaining_time': 89.7876363302532}\n",
      "2024-03-07 15:29:08,850 - DEBUG - utilities - Step (40) Logs: {'loss': 7.0718, 'grad_norm': 87.45474243164062, 'learning_rate': 0.00024120603015075377, 'epoch': 0.13, 'iter_time': 0.5581084398122934, 'flops': 3934124008392.457, 'remaining_time': 89.29735036996695}\n",
      "2024-03-07 15:29:09,386 - DEBUG - utilities - Step (41) Logs: {'loss': 6.9371, 'grad_norm': 123.1154556274414, 'learning_rate': 0.00023969849246231154, 'epoch': 0.13, 'iter_time': 0.5575634002685547, 'flops': 3937969765042.7554, 'remaining_time': 88.65258064270019}\n",
      "2024-03-07 15:29:09,978 - DEBUG - utilities - Step (42) Logs: {'loss': 4.8726, 'grad_norm': 86.21897888183594, 'learning_rate': 0.00023819095477386934, 'epoch': 0.13, 'iter_time': 0.5583912395849461, 'flops': 3932131553467.864, 'remaining_time': 88.22581585442148}\n",
      "2024-03-07 15:29:10,550 - DEBUG - utilities - Step (43) Logs: {'loss': 7.1032, 'grad_norm': 77.73214721679688, 'learning_rate': 0.0002366834170854271, 'epoch': 0.14, 'iter_time': 0.5587288084484282, 'flops': 3929755865729.026, 'remaining_time': 87.72042292640323}\n",
      "2024-03-07 15:29:11,157 - DEBUG - utilities - Step (44) Logs: {'loss': 7.6488, 'grad_norm': 103.12030029296875, 'learning_rate': 0.0002351758793969849, 'epoch': 0.14, 'iter_time': 0.5598517406818478, 'flops': 3921873690484.3394, 'remaining_time': 87.33687154636826}\n",
      "2024-03-07 15:29:11,757 - DEBUG - utilities - Step (45) Logs: {'loss': 5.7411, 'grad_norm': 71.53350067138672, 'learning_rate': 0.0002336683417085427, 'epoch': 0.14, 'iter_time': 0.560755269093947, 'flops': 3915554491177.051, 'remaining_time': 86.9170667095618}\n",
      "2024-03-07 15:29:12,315 - DEBUG - utilities - Step (46) Logs: {'loss': 8.4308, 'grad_norm': 127.22081756591797, 'learning_rate': 0.0002321608040201005, 'epoch': 0.15, 'iter_time': 0.560690975189209, 'flops': 3916003484113.61, 'remaining_time': 86.34641017913818}\n",
      "2024-03-07 15:29:12,866 - DEBUG - utilities - Step (47) Logs: {'loss': 6.6327, 'grad_norm': 80.33196258544922, 'learning_rate': 0.00023065326633165827, 'epoch': 0.15, 'iter_time': 0.5604751317397408, 'flops': 3917511568330.508, 'remaining_time': 85.75269515618035}\n",
      "2024-03-07 15:29:13,393 - DEBUG - utilities - Step (48) Logs: {'loss': 3.9791, 'grad_norm': 75.01652526855469, 'learning_rate': 0.00022914572864321606, 'epoch': 0.15, 'iter_time': 0.5597604031258441, 'flops': 3922513632780.8003, 'remaining_time': 85.0835812751283}\n",
      "2024-03-07 15:29:13,949 - DEBUG - utilities - Step (49) Logs: {'loss': 6.4195, 'grad_norm': 75.10292053222656, 'learning_rate': 0.00022763819095477384, 'epoch': 0.16, 'iter_time': 0.5596859802802404, 'flops': 3923035219235.985, 'remaining_time': 84.5125830223163}\n",
      "2024-03-07 15:29:14,530 - DEBUG - utilities - Step (50) Logs: {'loss': 6.1271, 'grad_norm': 106.5892562866211, 'learning_rate': 0.00022613065326633166, 'epoch': 0.16, 'iter_time': 0.5601249179061578, 'flops': 3919960962564.8857, 'remaining_time': 84.01873768592367}\n",
      "2024-03-07 15:29:15,067 - DEBUG - utilities - Step (51) Logs: {'loss': 4.931, 'grad_norm': 91.44011688232422, 'learning_rate': 0.00022462311557788943, 'epoch': 0.16, 'iter_time': 0.5596679592132568, 'flops': 3923161539278.612, 'remaining_time': 83.39052592277527}\n",
      "2024-03-07 15:29:15,642 - DEBUG - utilities - Step (52) Logs: {'loss': 5.9699, 'grad_norm': 77.82774353027344, 'learning_rate': 0.00022311557788944723, 'epoch': 0.17, 'iter_time': 0.5599695280486462, 'flops': 3921048739925.8193, 'remaining_time': 82.87549015119964}\n",
      "2024-03-07 15:29:16,165 - DEBUG - utilities - Step (53) Logs: {'loss': 7.4142, 'grad_norm': 136.56375122070312, 'learning_rate': 0.000221608040201005, 'epoch': 0.17, 'iter_time': 0.5592597264509934, 'flops': 3926025258935.5747, 'remaining_time': 82.21117978829604}\n",
      "2024-03-07 15:29:16,711 - DEBUG - utilities - Step (54) Logs: {'loss': 6.1031, 'grad_norm': 91.12284851074219, 'learning_rate': 0.0002201005025125628, 'epoch': 0.17, 'iter_time': 0.5590117337568751, 'flops': 3927766949712.9697, 'remaining_time': 81.61571312850376}\n",
      "2024-03-07 15:29:17,258 - DEBUG - utilities - Step (55) Logs: {'loss': 6.3667, 'grad_norm': 64.6778793334961, 'learning_rate': 0.0002185929648241206, 'epoch': 0.17, 'iter_time': 0.5587804449929131, 'flops': 3929392719496.2007, 'remaining_time': 81.0231645239724}\n",
      "2024-03-07 15:29:17,884 - DEBUG - utilities - Step (56) Logs: {'loss': 7.6425, 'grad_norm': 82.39395141601562, 'learning_rate': 0.0002170854271356784, 'epoch': 0.18, 'iter_time': 0.5599968563426625, 'flops': 3920857389614.4683, 'remaining_time': 80.6395473133434}\n",
      "2024-03-07 15:29:18,390 - DEBUG - utilities - Step (57) Logs: {'loss': 6.3489, 'grad_norm': 121.39983367919922, 'learning_rate': 0.00021557788944723616, 'epoch': 0.18, 'iter_time': 0.5590385156018394, 'flops': 3927578782274.4707, 'remaining_time': 79.94250773106303}\n",
      "2024-03-07 15:29:18,955 - DEBUG - utilities - Step (58) Logs: {'loss': 4.4359, 'grad_norm': 64.15426635742188, 'learning_rate': 0.00021407035175879396, 'epoch': 0.18, 'iter_time': 0.5591476841976768, 'flops': 3926811957564.6143, 'remaining_time': 79.3989711560701}\n",
      "2024-03-07 15:29:19,518 - DEBUG - utilities - Step (59) Logs: {'loss': 6.305, 'grad_norm': 83.88140869140625, 'learning_rate': 0.00021256281407035173, 'epoch': 0.19, 'iter_time': 0.5592042372144502, 'flops': 3926414834210.17, 'remaining_time': 78.84779744723748}\n",
      "2024-03-07 15:29:20,052 - DEBUG - utilities - Step (60) Logs: {'loss': 4.8132, 'grad_norm': 91.18669891357422, 'learning_rate': 0.00021105527638190955, 'epoch': 0.19, 'iter_time': 0.558788659208912, 'flops': 3929334957263.5386, 'remaining_time': 78.23041228924768}\n",
      "2024-03-07 15:29:20,597 - DEBUG - utilities - Step (61) Logs: {'loss': 5.6003, 'grad_norm': 62.50172424316406, 'learning_rate': 0.00020954773869346732, 'epoch': 0.19, 'iter_time': 0.5585549672444662, 'flops': 3930978938713.848, 'remaining_time': 77.6391404469808}\n",
      "2024-03-07 15:29:21,126 - DEBUG - utilities - Step (62) Logs: {'loss': 6.8097, 'grad_norm': 71.0215835571289, 'learning_rate': 0.00020804020100502512, 'epoch': 0.2, 'iter_time': 0.5580616700844686, 'flops': 3934453717309.885, 'remaining_time': 77.01251047165667}\n",
      "2024-03-07 15:29:21,649 - DEBUG - utilities - Step (63) Logs: {'loss': 5.6195, 'grad_norm': 73.36689758300781, 'learning_rate': 0.0002065326633165829, 'epoch': 0.2, 'iter_time': 0.5575100606487643, 'flops': 3938346529203.332, 'remaining_time': 76.37887830888072}\n",
      "2024-03-07 15:29:22,200 - DEBUG - utilities - Step (64) Logs: {'loss': 5.7747, 'grad_norm': 88.07489776611328, 'learning_rate': 0.00020502512562814069, 'epoch': 0.2, 'iter_time': 0.5573966957273937, 'flops': 3939147521293.948, 'remaining_time': 75.80595061892555}\n",
      "2024-03-07 15:29:22,710 - DEBUG - utilities - Step (65) Logs: {'loss': 4.9974, 'grad_norm': 72.8936767578125, 'learning_rate': 0.00020351758793969848, 'epoch': 0.21, 'iter_time': 0.5566512160003185, 'flops': 3944422915534.8574, 'remaining_time': 75.147914160043}\n",
      "2024-03-07 15:29:23,259 - DEBUG - utilities - Step (66) Logs: {'loss': 6.6618, 'grad_norm': 110.7381362915039, 'learning_rate': 0.00020201005025125628, 'epoch': 0.21, 'iter_time': 0.556547814149123, 'flops': 3945155755770.674, 'remaining_time': 74.57740709598248}\n",
      "2024-03-07 15:29:23,824 - DEBUG - utilities - Step (67) Logs: {'loss': 6.7876, 'grad_norm': 69.74980926513672, 'learning_rate': 0.00020050251256281405, 'epoch': 0.21, 'iter_time': 0.5566721070896495, 'flops': 3944274887116.623, 'remaining_time': 74.0373902429234}\n",
      "2024-03-07 15:29:24,366 - DEBUG - utilities - Step (68) Logs: {'loss': 5.0517, 'grad_norm': 91.7051773071289, 'learning_rate': 0.00019899497487437185, 'epoch': 0.22, 'iter_time': 0.5564535802869655, 'flops': 3945823856896.895, 'remaining_time': 73.45187259787944}\n",
      "2024-03-07 15:29:24,880 - DEBUG - utilities - Step (69) Logs: {'loss': 6.2831, 'grad_norm': 90.07796478271484, 'learning_rate': 0.00019748743718592962, 'epoch': 0.22, 'iter_time': 0.5558296757585862, 'flops': 3950252942783.943, 'remaining_time': 72.8136875243748}\n",
      "2024-03-07 15:29:25,419 - DEBUG - utilities - Step (70) Logs: {'loss': 5.11, 'grad_norm': 90.225341796875, 'learning_rate': 0.00019597989949748744, 'epoch': 0.22, 'iter_time': 0.5555749837903009, 'flops': 3952063855309.843, 'remaining_time': 72.22474789273912}\n",
      "2024-03-07 15:29:25,981 - DEBUG - utilities - Step (71) Logs: {'loss': 5.4379, 'grad_norm': 70.7110366821289, 'learning_rate': 0.0001944723618090452, 'epoch': 0.23, 'iter_time': 0.5556796414511544, 'flops': 3951319516795.73, 'remaining_time': 71.68267374719892}\n",
      "2024-03-07 15:29:26,528 - DEBUG - utilities - Step (72) Logs: {'loss': 5.1163, 'grad_norm': 70.3118896484375, 'learning_rate': 0.000192964824120603, 'epoch': 0.23, 'iter_time': 0.5555545746440619, 'flops': 3952209040414.692, 'remaining_time': 71.11098555443992}\n",
      "2024-03-07 15:29:27,103 - DEBUG - utilities - Step (73) Logs: {'loss': 5.883, 'grad_norm': 81.19807434082031, 'learning_rate': 0.00019145728643216078, 'epoch': 0.23, 'iter_time': 0.5558212200800577, 'flops': 3950313037770.9346, 'remaining_time': 70.58929495016733}\n",
      "2024-03-07 15:29:27,606 - DEBUG - utilities - Step (74) Logs: {'loss': 4.149, 'grad_norm': 51.397705078125, 'learning_rate': 0.00018994974874371858, 'epoch': 0.23, 'iter_time': 0.5551003527967897, 'flops': 3955443013663.129, 'remaining_time': 69.9426444523955}\n",
      "2024-03-07 15:29:28,158 - DEBUG - utilities - Step (75) Logs: {'loss': 5.9799, 'grad_norm': 110.36469268798828, 'learning_rate': 0.00018844221105527637, 'epoch': 0.24, 'iter_time': 0.5550595683020514, 'flops': 3955733650477.61, 'remaining_time': 69.38244603775642}\n",
      "2024-03-07 15:29:28,752 - DEBUG - utilities - Step (76) Logs: {'loss': 6.105, 'grad_norm': 91.80604553222656, 'learning_rate': 0.00018693467336683417, 'epoch': 0.24, 'iter_time': 0.555572026570638, 'flops': 3952084891503.861, 'remaining_time': 68.89093129475911}\n",
      "2024-03-07 15:29:29,374 - DEBUG - utilities - Step (77) Logs: {'loss': 6.0441, 'grad_norm': 59.81145477294922, 'learning_rate': 0.00018542713567839194, 'epoch': 0.24, 'iter_time': 0.5564460503427606, 'flops': 3945877252609.68, 'remaining_time': 68.44286419215956}\n",
      "2024-03-07 15:29:29,916 - DEBUG - utilities - Step (78) Logs: {'loss': 7.2902, 'grad_norm': 119.46359252929688, 'learning_rate': 0.00018391959798994974, 'epoch': 0.25, 'iter_time': 0.5562616633130358, 'flops': 3947185213654.369, 'remaining_time': 67.86392292419038}\n",
      "2024-03-07 15:29:30,489 - DEBUG - utilities - Step (79) Logs: {'loss': 5.2434, 'grad_norm': 61.36624526977539, 'learning_rate': 0.0001824120603015075, 'epoch': 0.25, 'iter_time': 0.5564791911687607, 'flops': 3945642257962.0425, 'remaining_time': 67.33398213142004}\n",
      "2024-03-07 15:29:31,094 - DEBUG - utilities - Step (80) Logs: {'loss': 6.1997, 'grad_norm': 96.45838165283203, 'learning_rate': 0.0001809045226130653, 'epoch': 0.25, 'iter_time': 0.5570932400377491, 'flops': 3941293224457.7583, 'remaining_time': 66.85118880452988}\n",
      "2024-03-07 15:29:31,648 - DEBUG - utilities - Step (81) Logs: {'loss': 5.6798, 'grad_norm': 58.504642486572266, 'learning_rate': 0.0001793969849246231, 'epoch': 0.26, 'iter_time': 0.5570538848638534, 'flops': 3941571671991.178, 'remaining_time': 66.28941229879855}\n",
      "2024-03-07 15:29:32,207 - DEBUG - utilities - Step (82) Logs: {'loss': 6.5289, 'grad_norm': 90.8530044555664, 'learning_rate': 0.0001778894472361809, 'epoch': 0.26, 'iter_time': 0.557077975920689, 'flops': 3941401217169.276, 'remaining_time': 65.7352011586413}\n",
      "2024-03-07 15:29:32,773 - DEBUG - utilities - Step (83) Logs: {'loss': 5.4445, 'grad_norm': 85.17132568359375, 'learning_rate': 0.00017638190954773867, 'epoch': 0.26, 'iter_time': 0.5571904269660392, 'flops': 3940605771545.006, 'remaining_time': 65.19127995502659}\n",
      "2024-03-07 15:29:33,351 - DEBUG - utilities - Step (84) Logs: {'loss': 5.2363, 'grad_norm': 65.3005142211914, 'learning_rate': 0.00017487437185929647, 'epoch': 0.27, 'iter_time': 0.5574407807315689, 'flops': 3938835995225.3047, 'remaining_time': 64.66313056486199}\n",
      "2024-03-07 15:29:33,901 - DEBUG - utilities - Step (85) Logs: {'loss': 5.9231, 'grad_norm': 71.78568267822266, 'learning_rate': 0.00017336683417085424, 'epoch': 0.27, 'iter_time': 0.5573413684254601, 'flops': 3939538560640.0625, 'remaining_time': 64.09425736892791}\n",
      "2024-03-07 15:29:34,471 - DEBUG - utilities - Step (86) Logs: {'loss': 4.8447, 'grad_norm': 60.70295333862305, 'learning_rate': 0.00017185929648241206, 'epoch': 0.27, 'iter_time': 0.5574959053712732, 'flops': 3938446527046.2573, 'remaining_time': 63.55453321232515}\n",
      "2024-03-07 15:29:34,992 - DEBUG - utilities - Step (87) Logs: {'loss': 4.76, 'grad_norm': 60.314571380615234, 'learning_rate': 0.00017035175879396983, 'epoch': 0.28, 'iter_time': 0.5570712644000386, 'flops': 3941448702647.976, 'remaining_time': 62.949052877204366}\n",
      "2024-03-07 15:29:35,553 - DEBUG - utilities - Step (88) Logs: {'loss': 7.152, 'grad_norm': 74.4603271484375, 'learning_rate': 0.00016884422110552763, 'epoch': 0.28, 'iter_time': 0.5571192653699854, 'flops': 3941109110441.276, 'remaining_time': 62.39735772143836}\n",
      "2024-03-07 15:29:36,148 - DEBUG - utilities - Step (89) Logs: {'loss': 5.1003, 'grad_norm': 78.48058319091797, 'learning_rate': 0.0001673366834170854, 'epoch': 0.28, 'iter_time': 0.5575432262637399, 'flops': 3938112255556.958, 'remaining_time': 61.88729811527512}\n",
      "2024-03-07 15:29:36,740 - DEBUG - utilities - Step (90) Logs: {'loss': 4.2049, 'grad_norm': 59.432247161865234, 'learning_rate': 0.0001658291457286432, 'epoch': 0.29, 'iter_time': 0.5579383453626311, 'flops': 3935323375067.418, 'remaining_time': 61.37321798988942}\n",
      "2024-03-07 15:29:37,253 - DEBUG - utilities - Step (91) Logs: {'loss': 4.5691, 'grad_norm': 74.24030303955078, 'learning_rate': 0.000164321608040201, 'epoch': 0.29, 'iter_time': 0.5574308554331462, 'flops': 3938906127910.4795, 'remaining_time': 60.75996324221293}\n",
      "2024-03-07 15:29:37,856 - DEBUG - utilities - Step (92) Logs: {'loss': 5.1656, 'grad_norm': 56.550777435302734, 'learning_rate': 0.0001628140703517588, 'epoch': 0.29, 'iter_time': 0.557933393415514, 'flops': 3935358303095.516, 'remaining_time': 60.256806488875505}\n",
      "2024-03-07 15:29:38,409 - DEBUG - utilities - Step (93) Logs: {'loss': 5.0525, 'grad_norm': 75.56806945800781, 'learning_rate': 0.00016130653266331656, 'epoch': 0.3, 'iter_time': 0.5578868363214575, 'flops': 3935686718886.559, 'remaining_time': 59.693891486395955}\n",
      "2024-03-07 15:29:38,958 - DEBUG - utilities - Step (94) Logs: {'loss': 5.5649, 'grad_norm': 53.20581817626953, 'learning_rate': 0.00015979899497487436, 'epoch': 0.3, 'iter_time': 0.5577855263986895, 'flops': 3936401552991.5312, 'remaining_time': 59.12526579826109}\n",
      "2024-03-07 15:29:39,528 - DEBUG - utilities - Step (95) Logs: {'loss': 5.7162, 'grad_norm': 100.58020782470703, 'learning_rate': 0.00015829145728643213, 'epoch': 0.3, 'iter_time': 0.5579217773802737, 'flops': 3935440237987.799, 'remaining_time': 58.58178662492874}\n",
      "2024-03-07 15:29:40,104 - DEBUG - utilities - Step (96) Logs: {'loss': 4.0791, 'grad_norm': 55.96183776855469, 'learning_rate': 0.00015678391959798995, 'epoch': 0.3, 'iter_time': 0.5581055465497469, 'flops': 3934144403197.198, 'remaining_time': 58.042976841173676}\n",
      "2024-03-07 15:29:40,642 - DEBUG - utilities - Step (97) Logs: {'loss': 5.3242, 'grad_norm': 89.18016815185547, 'learning_rate': 0.00015527638190954772, 'epoch': 0.31, 'iter_time': 0.5579008335868517, 'flops': 3935587975797.8306, 'remaining_time': 57.46378585944573}\n",
      "2024-03-07 15:29:41,169 - DEBUG - utilities - Step (98) Logs: {'loss': 4.1818, 'grad_norm': 47.19319534301758, 'learning_rate': 0.00015376884422110552, 'epoch': 0.31, 'iter_time': 0.5575794411688736, 'flops': 3937856474315.3794, 'remaining_time': 56.873102999225104}\n",
      "2024-03-07 15:29:41,700 - DEBUG - utilities - Step (99) Logs: {'loss': 4.1007, 'grad_norm': 54.04032516479492, 'learning_rate': 0.0001522613065326633, 'epoch': 0.31, 'iter_time': 0.5573104182068183, 'flops': 3939757342804.9326, 'remaining_time': 56.28835223888864}\n",
      "2024-03-07 15:29:42,283 - DEBUG - utilities - Step (100) Logs: {'loss': 5.5472, 'grad_norm': 57.5698356628418, 'learning_rate': 0.0001507537688442211, 'epoch': 0.32, 'iter_time': 0.5575712016134551, 'flops': 3937914666321.2725, 'remaining_time': 55.75712016134551}\n",
      "2024-03-07 15:29:42,774 - DEBUG - utilities - Step (101) Logs: {'loss': 4.1744, 'grad_norm': 52.15323257446289, 'learning_rate': 0.00014924623115577889, 'epoch': 0.32, 'iter_time': 0.5568968510627746, 'flops': 3942683116562.459, 'remaining_time': 55.13278825521469}\n",
      "2024-03-07 15:29:43,328 - DEBUG - utilities - Step (102) Logs: {'loss': 5.4344, 'grad_norm': 58.92264938354492, 'learning_rate': 0.00014773869346733668, 'epoch': 0.32, 'iter_time': 0.5568712465833909, 'flops': 3942864397871.548, 'remaining_time': 54.57338216517231}\n",
      "2024-03-07 15:29:43,851 - DEBUG - utilities - Step (103) Logs: {'loss': 4.8328, 'grad_norm': 59.0441780090332, 'learning_rate': 0.00014623115577889445, 'epoch': 0.33, 'iter_time': 0.5565453627530266, 'flops': 3945173132861.6836, 'remaining_time': 53.98490018704358}\n",
      "2024-03-07 15:29:44,386 - DEBUG - utilities - Step (104) Logs: {'loss': 4.6526, 'grad_norm': 64.05934143066406, 'learning_rate': 0.00014472361809045225, 'epoch': 0.33, 'iter_time': 0.5563270397556638, 'flops': 3946721362521.453, 'remaining_time': 53.407395816543726}\n",
      "2024-03-07 15:29:44,908 - DEBUG - utilities - Step (105) Logs: {'loss': 5.5167, 'grad_norm': 100.23652648925781, 'learning_rate': 0.00014321608040201005, 'epoch': 0.33, 'iter_time': 0.556005576482186, 'flops': 3949003220873.8965, 'remaining_time': 52.82052976580766}\n",
      "2024-03-07 15:29:45,649 - DEBUG - utilities - Step (106) Logs: {'loss': 4.5303, 'grad_norm': 32.40332794189453, 'learning_rate': 0.00014170854271356782, 'epoch': 0.34, 'iter_time': 0.5577601319267637, 'flops': 3936580774906.1216, 'remaining_time': 52.42945240111578}\n",
      "2024-03-07 15:29:46,217 - DEBUG - utilities - Step (107) Logs: {'loss': 5.1735, 'grad_norm': 60.35395431518555, 'learning_rate': 0.00014020100502512561, 'epoch': 0.34, 'iter_time': 0.55785840637279, 'flops': 3935887291953.328, 'remaining_time': 51.880831792669476}\n",
      "2024-03-07 15:29:46,759 - DEBUG - utilities - Step (108) Logs: {'loss': 5.0861, 'grad_norm': 51.83389663696289, 'learning_rate': 0.0001386934673366834, 'epoch': 0.34, 'iter_time': 0.5577089430015778, 'flops': 3936942091218.6953, 'remaining_time': 51.30922275614516}\n",
      "2024-03-07 15:29:47,324 - DEBUG - utilities - Step (109) Logs: {'loss': 4.3825, 'grad_norm': 97.7666244506836, 'learning_rate': 0.00013718592964824118, 'epoch': 0.35, 'iter_time': 0.5577819722670095, 'flops': 3936426635353.7446, 'remaining_time': 50.75815947629787}\n",
      "2024-03-07 15:29:47,857 - DEBUG - utilities - Step (110) Logs: {'loss': 2.9188, 'grad_norm': 42.67974853515625, 'learning_rate': 0.00013567839195979898, 'epoch': 0.35, 'iter_time': 0.5575532563235781, 'flops': 3938041411200.612, 'remaining_time': 50.17979306912203}\n",
      "2024-03-07 15:29:48,418 - DEBUG - utilities - Step (111) Logs: {'loss': 3.5456, 'grad_norm': 49.81270980834961, 'learning_rate': 0.00013417085427135678, 'epoch': 0.35, 'iter_time': 0.5575788086110895, 'flops': 3937860941704.969, 'remaining_time': 49.62451396638697}\n",
      "2024-03-07 15:29:49,012 - DEBUG - utilities - Step (112) Logs: {'loss': 4.2628, 'grad_norm': 55.624759674072266, 'learning_rate': 0.00013266331658291457, 'epoch': 0.36, 'iter_time': 0.5579107022500253, 'flops': 3935518360728.669, 'remaining_time': 49.09614179800222}\n",
      "2024-03-07 15:29:49,591 - DEBUG - utilities - Step (113) Logs: {'loss': 4.4399, 'grad_norm': 51.050106048583984, 'learning_rate': 0.00013115577889447234, 'epoch': 0.36, 'iter_time': 0.5580993316003254, 'flops': 3934188213513.9253, 'remaining_time': 48.55464184922831}\n",
      "2024-03-07 15:29:50,171 - DEBUG - utilities - Step (114) Logs: {'loss': 4.9876, 'grad_norm': 56.350364685058594, 'learning_rate': 0.00012964824120603014, 'epoch': 0.36, 'iter_time': 0.5582895637613482, 'flops': 3932847674169.6377, 'remaining_time': 48.01290248347595}\n",
      "2024-03-07 15:29:50,734 - DEBUG - utilities - Step (115) Logs: {'loss': 4.0998, 'grad_norm': 65.63440704345703, 'learning_rate': 0.00012814070351758794, 'epoch': 0.37, 'iter_time': 0.5583332086864271, 'flops': 3932540243339.0596, 'remaining_time': 47.458322738346304}\n",
      "2024-03-07 15:29:51,254 - DEBUG - utilities - Step (116) Logs: {'loss': 4.3709, 'grad_norm': 62.85039520263672, 'learning_rate': 0.0001266331658291457, 'epoch': 0.37, 'iter_time': 0.5580012673917024, 'flops': 3934879615265.637, 'remaining_time': 46.872106460903005}\n",
      "2024-03-07 15:29:51,816 - DEBUG - utilities - Step (117) Logs: {'loss': 3.9419, 'grad_norm': 84.6861343383789, 'learning_rate': 0.0001251256281407035, 'epoch': 0.37, 'iter_time': 0.5580321879222475, 'flops': 3934661583818.763, 'remaining_time': 46.316671597546545}\n",
      "2024-03-07 15:29:52,337 - DEBUG - utilities - Step (118) Logs: {'loss': 3.7532, 'grad_norm': 68.52285766601562, 'learning_rate': 0.0001236180904522613, 'epoch': 0.37, 'iter_time': 0.5577182810530703, 'flops': 3936876173766.785, 'remaining_time': 45.73289904635177}\n",
      "2024-03-07 15:29:52,903 - DEBUG - utilities - Step (119) Logs: {'loss': 3.2444, 'grad_norm': 45.51009750366211, 'learning_rate': 0.00012211055276381907, 'epoch': 0.38, 'iter_time': 0.5577870001227169, 'flops': 3936391152660.3135, 'remaining_time': 45.18074700994006}\n",
      "2024-03-07 15:29:53,455 - DEBUG - utilities - Step (120) Logs: {'loss': 4.5797, 'grad_norm': 89.90814971923828, 'learning_rate': 0.00012060301507537688, 'epoch': 0.38, 'iter_time': 0.5577395543330858, 'flops': 3936726013591.5205, 'remaining_time': 44.61916434664686}\n",
      "2024-03-07 15:29:57,292 - DEBUG - utilities - Step (120) Logs: {'eval_loss': 4.311736583709717, 'eval_runtime': 3.8273, 'eval_samples_per_second': 36.579, 'eval_steps_per_second': 36.579, 'epoch': 0.38, 'iter_time': 0.5899883939438507, 'flops': 3721544075934.7583, 'remaining_time': 47.19907151550806}\n",
      "Checkpoint destination directory lamini_docs_200_steps/checkpoint-120 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "2024-03-07 15:29:58,360 - DEBUG - utilities - Step (121) Logs: {'loss': 5.2164, 'grad_norm': 62.72712326049805, 'learning_rate': 0.00011909547738693467, 'epoch': 0.38, 'iter_time': 0.5939688841501872, 'flops': 3696604099882.1367, 'remaining_time': 46.92354184786479}\n",
      "2024-03-07 15:29:58,903 - DEBUG - utilities - Step (122) Logs: {'loss': 3.4486, 'grad_norm': 46.33740234375, 'learning_rate': 0.00011758793969849245, 'epoch': 0.39, 'iter_time': 0.5935456122248626, 'flops': 3699240238878.5234, 'remaining_time': 46.29655775353928}\n",
      "2024-03-07 15:29:59,443 - DEBUG - utilities - Step (123) Logs: {'loss': 4.4122, 'grad_norm': 52.52537536621094, 'learning_rate': 0.00011608040201005025, 'epoch': 0.39, 'iter_time': 0.5931071062557033, 'flops': 3701975223688.1694, 'remaining_time': 45.66924718168915}\n",
      "2024-03-07 15:30:00,062 - DEBUG - utilities - Step (124) Logs: {'loss': 4.186, 'grad_norm': 42.9281120300293, 'learning_rate': 0.00011457286432160803, 'epoch': 0.39, 'iter_time': 0.5933210733460217, 'flops': 3700640194641.2886, 'remaining_time': 45.09240157429765}\n",
      "2024-03-07 15:30:00,608 - DEBUG - utilities - Step (125) Logs: {'loss': 4.3986, 'grad_norm': 43.036869049072266, 'learning_rate': 0.00011306532663316583, 'epoch': 0.4, 'iter_time': 0.5929350545329433, 'flops': 3703049424327.82, 'remaining_time': 44.47012908997075}\n",
      "2024-03-07 15:30:01,170 - DEBUG - utilities - Step (126) Logs: {'loss': 4.5338, 'grad_norm': 49.293392181396484, 'learning_rate': 0.00011155778894472361, 'epoch': 0.4, 'iter_time': 0.5926921501159668, 'flops': 3704567053777.232, 'remaining_time': 43.85921910858154}\n",
      "2024-03-07 15:30:01,750 - DEBUG - utilities - Step (127) Logs: {'loss': 3.9615, 'grad_norm': 42.9732551574707, 'learning_rate': 0.0001100502512562814, 'epoch': 0.4, 'iter_time': 0.5925884757723127, 'flops': 3705215173971.136, 'remaining_time': 43.258958731378826}\n",
      "2024-03-07 15:30:02,273 - DEBUG - utilities - Step (128) Logs: {'loss': 3.694, 'grad_norm': 40.02465057373047, 'learning_rate': 0.0001085427135678392, 'epoch': 0.41, 'iter_time': 0.5920371014302171, 'flops': 3708665904633.008, 'remaining_time': 42.62667130297564}\n",
      "2024-03-07 15:30:02,802 - DEBUG - utilities - Step (129) Logs: {'loss': 4.0022, 'grad_norm': 46.7675895690918, 'learning_rate': 0.00010703517587939698, 'epoch': 0.41, 'iter_time': 0.5915489140897989, 'flops': 3711726553890.1675, 'remaining_time': 41.999972900375724}\n",
      "2024-03-07 15:30:03,378 - DEBUG - utilities - Step (130) Logs: {'loss': 3.8835, 'grad_norm': 43.62510299682617, 'learning_rate': 0.00010552763819095478, 'epoch': 0.41, 'iter_time': 0.5914267052051633, 'flops': 3712493522913.0933, 'remaining_time': 41.39986936436143}\n",
      "2024-03-07 15:30:03,969 - DEBUG - utilities - Step (131) Logs: {'loss': 4.3381, 'grad_norm': 36.174007415771484, 'learning_rate': 0.00010402010050251256, 'epoch': 0.42, 'iter_time': 0.5914257526397705, 'flops': 3712499502349.7935, 'remaining_time': 40.808376932144164}\n",
      "2024-03-07 15:30:04,528 - DEBUG - utilities - Step (132) Logs: {'loss': 2.6941, 'grad_norm': 44.57536697387695, 'learning_rate': 0.00010251256281407034, 'epoch': 0.42, 'iter_time': 0.5911789977823505, 'flops': 3714049079193.373, 'remaining_time': 40.20017184919983}\n",
      "2024-03-07 15:30:05,068 - DEBUG - utilities - Step (133) Logs: {'loss': 4.0159, 'grad_norm': 52.3868293762207, 'learning_rate': 0.00010100502512562814, 'epoch': 0.42, 'iter_time': 0.5907901814489653, 'flops': 3716493403744.3374, 'remaining_time': 39.58294215708068}\n",
      "2024-03-07 15:30:05,690 - DEBUG - utilities - Step (134) Logs: {'loss': 5.4168, 'grad_norm': 57.355472564697266, 'learning_rate': 9.949748743718592e-05, 'epoch': 0.43, 'iter_time': 0.5910247878024453, 'flops': 3715018147573.735, 'remaining_time': 39.00763599496139}\n",
      "2024-03-07 15:30:06,259 - DEBUG - utilities - Step (135) Logs: {'loss': 3.5863, 'grad_norm': 60.118019104003906, 'learning_rate': 9.798994974874372e-05, 'epoch': 0.43, 'iter_time': 0.5908568492576257, 'flops': 3716074062796.628, 'remaining_time': 38.40569520174567}\n",
      "2024-03-07 15:30:06,789 - DEBUG - utilities - Step (136) Logs: {'loss': 4.1381, 'grad_norm': 48.227298736572266, 'learning_rate': 9.64824120603015e-05, 'epoch': 0.43, 'iter_time': 0.5904114440635398, 'flops': 3718877461521.0596, 'remaining_time': 37.78633242006655}\n",
      "2024-03-07 15:30:07,335 - DEBUG - utilities - Step (137) Logs: {'loss': 4.2725, 'grad_norm': 42.323909759521484, 'learning_rate': 9.497487437185929e-05, 'epoch': 0.43, 'iter_time': 0.5900805522413815, 'flops': 3720962848227.929, 'remaining_time': 37.17507479120703}\n",
      "2024-03-07 15:30:07,879 - DEBUG - utilities - Step (138) Logs: {'loss': 3.6153, 'grad_norm': 41.049720764160156, 'learning_rate': 9.346733668341709e-05, 'epoch': 0.44, 'iter_time': 0.5897425317416226, 'flops': 3723095578451.4517, 'remaining_time': 36.5640369679806}\n",
      "2024-03-07 15:30:08,479 - DEBUG - utilities - Step (139) Logs: {'loss': 3.6922, 'grad_norm': 35.66767883300781, 'learning_rate': 9.195979899497487e-05, 'epoch': 0.44, 'iter_time': 0.5898182236629984, 'flops': 3722617790132.114, 'remaining_time': 35.978911643442906}\n",
      "2024-03-07 15:30:09,035 - DEBUG - utilities - Step (140) Logs: {'loss': 3.397, 'grad_norm': 40.4074821472168, 'learning_rate': 9.045226130653265e-05, 'epoch': 0.44, 'iter_time': 0.5895767486352714, 'flops': 3724142475825.995, 'remaining_time': 35.37460491811628}\n",
      "2024-03-07 15:30:09,586 - DEBUG - utilities - Step (141) Logs: {'loss': 3.4029, 'grad_norm': 40.359413146972656, 'learning_rate': 8.894472361809045e-05, 'epoch': 0.45, 'iter_time': 0.5892988273075649, 'flops': 3725898831979.254, 'remaining_time': 34.76863081114633}\n",
      "2024-03-07 15:30:10,223 - DEBUG - utilities - Step (142) Logs: {'loss': 4.5655, 'grad_norm': 42.26887512207031, 'learning_rate': 8.743718592964823e-05, 'epoch': 0.45, 'iter_time': 0.5896413681354928, 'flops': 3723734342613.934, 'remaining_time': 34.19919935185858}\n",
      "2024-03-07 15:30:10,808 - DEBUG - utilities - Step (143) Logs: {'loss': 4.0689, 'grad_norm': 38.4630126953125, 'learning_rate': 8.592964824120603e-05, 'epoch': 0.45, 'iter_time': 0.5896073311147555, 'flops': 3723949307415.6777, 'remaining_time': 33.607617873541066}\n",
      "2024-03-07 15:30:11,354 - DEBUG - utilities - Step (144) Logs: {'loss': 3.2567, 'grad_norm': 44.06555938720703, 'learning_rate': 8.442211055276381e-05, 'epoch': 0.46, 'iter_time': 0.5893030500078534, 'flops': 3725872133739.574, 'remaining_time': 33.000970800439795}\n",
      "2024-03-07 15:30:11,926 - DEBUG - utilities - Step (145) Logs: {'loss': 5.9146, 'grad_norm': 64.6846923828125, 'learning_rate': 8.29145728643216e-05, 'epoch': 0.46, 'iter_time': 0.5891821516884698, 'flops': 3726636670950.8877, 'remaining_time': 32.40501834286584}\n",
      "2024-03-07 15:30:12,482 - DEBUG - utilities - Step (146) Logs: {'loss': 2.7924, 'grad_norm': 29.02463150024414, 'learning_rate': 8.14070351758794e-05, 'epoch': 0.46, 'iter_time': 0.5889558265949117, 'flops': 3728068750158.0605, 'remaining_time': 31.803614636125236}\n",
      "2024-03-07 15:30:13,019 - DEBUG - utilities - Step (147) Logs: {'loss': 4.9949, 'grad_norm': 60.40904998779297, 'learning_rate': 7.989949748743718e-05, 'epoch': 0.47, 'iter_time': 0.5885999594649224, 'flops': 3730322737956.034, 'remaining_time': 31.195797851640886}\n",
      "2024-03-07 15:30:13,589 - DEBUG - utilities - Step (148) Logs: {'loss': 3.7743, 'grad_norm': 35.26558303833008, 'learning_rate': 7.839195979899498e-05, 'epoch': 0.47, 'iter_time': 0.5884696934498898, 'flops': 3731148497180.7964, 'remaining_time': 30.600424059394268}\n",
      "2024-03-07 15:30:14,139 - DEBUG - utilities - Step (149) Logs: {'loss': 4.3944, 'grad_norm': 40.94267654418945, 'learning_rate': 7.688442211055276e-05, 'epoch': 0.47, 'iter_time': 0.5882121807820088, 'flops': 3732781951970.005, 'remaining_time': 29.998821219882448}\n",
      "2024-03-07 15:30:14,723 - DEBUG - utilities - Step (150) Logs: {'loss': 3.1729, 'grad_norm': 27.658550262451172, 'learning_rate': 7.537688442211054e-05, 'epoch': 0.48, 'iter_time': 0.5881819805042856, 'flops': 3732973612128.5376, 'remaining_time': 29.40909902521428}\n",
      "2024-03-07 15:30:15,291 - DEBUG - utilities - Step (151) Logs: {'loss': 4.8914, 'grad_norm': 47.26972198486328, 'learning_rate': 7.386934673366834e-05, 'epoch': 0.48, 'iter_time': 0.588046293258667, 'flops': 3733834967625.891, 'remaining_time': 28.814268369674682}\n",
      "2024-03-07 15:30:15,829 - DEBUG - utilities - Step (152) Logs: {'loss': 4.2335, 'grad_norm': 43.05695724487305, 'learning_rate': 7.236180904522613e-05, 'epoch': 0.48, 'iter_time': 0.5877191057268357, 'flops': 3735913620906.7163, 'remaining_time': 28.210517074888116}\n",
      "2024-03-07 15:30:16,380 - DEBUG - utilities - Step (153) Logs: {'loss': 3.4819, 'grad_norm': 36.18162536621094, 'learning_rate': 7.085427135678391e-05, 'epoch': 0.49, 'iter_time': 0.5874735399296409, 'flops': 3737475244612.66, 'remaining_time': 27.611256376693124}\n",
      "2024-03-07 15:30:16,958 - DEBUG - utilities - Step (154) Logs: {'loss': 2.8564, 'grad_norm': 35.433448791503906, 'learning_rate': 6.93467336683417e-05, 'epoch': 0.49, 'iter_time': 0.5874119288001964, 'flops': 3737867252435.1123, 'remaining_time': 27.020948724809035}\n",
      "2024-03-07 15:30:17,540 - DEBUG - utilities - Step (155) Logs: {'loss': 3.2724, 'grad_norm': 40.428627014160156, 'learning_rate': 6.783919597989949e-05, 'epoch': 0.49, 'iter_time': 0.5873804603304181, 'flops': 3738067505883.452, 'remaining_time': 26.432120714868816}\n",
      "2024-03-07 15:30:18,117 - DEBUG - utilities - Step (156) Logs: {'loss': 2.9806, 'grad_norm': 36.668487548828125, 'learning_rate': 6.633165829145729e-05, 'epoch': 0.5, 'iter_time': 0.5873131936596286, 'flops': 3738495637515.8105, 'remaining_time': 25.84178052102366}\n",
      "2024-03-07 15:30:18,690 - DEBUG - utilities - Step (157) Logs: {'loss': 3.7153, 'grad_norm': 64.94277954101562, 'learning_rate': 6.482412060301507e-05, 'epoch': 0.5, 'iter_time': 0.5872194170951843, 'flops': 3739092660139.501, 'remaining_time': 25.250434935092926}\n",
      "2024-03-07 15:30:19,230 - DEBUG - utilities - Step (158) Logs: {'loss': 2.6332, 'grad_norm': 32.91380310058594, 'learning_rate': 6.331658291457285e-05, 'epoch': 0.5, 'iter_time': 0.5869192484837429, 'flops': 3741004947485.2383, 'remaining_time': 24.6506084363172}\n",
      "2024-03-07 15:30:19,772 - DEBUG - utilities - Step (159) Logs: {'loss': 3.4182, 'grad_norm': 43.19860076904297, 'learning_rate': 6.180904522613065e-05, 'epoch': 0.5, 'iter_time': 0.5866346253624445, 'flops': 3742820006567.8623, 'remaining_time': 24.052019639860223}\n",
      "2024-03-07 15:30:20,350 - DEBUG - utilities - Step (160) Logs: {'loss': 4.192, 'grad_norm': 35.6058235168457, 'learning_rate': 6.030150753768844e-05, 'epoch': 0.51, 'iter_time': 0.586581288643603, 'flops': 3743160334059.089, 'remaining_time': 23.46325154574412}\n",
      "2024-03-07 15:30:20,909 - DEBUG - utilities - Step (161) Logs: {'loss': 2.6893, 'grad_norm': 33.02766799926758, 'learning_rate': 5.8793969849246226e-05, 'epoch': 0.51, 'iter_time': 0.5864043682813644, 'flops': 3744289659347.3022, 'remaining_time': 22.869770362973213}\n",
      "2024-03-07 15:30:21,434 - DEBUG - utilities - Step (162) Logs: {'loss': 3.0944, 'grad_norm': 33.57920837402344, 'learning_rate': 5.7286432160804016e-05, 'epoch': 0.51, 'iter_time': 0.5860285151819264, 'flops': 3746691083232.32, 'remaining_time': 22.269083576913204}\n",
      "2024-03-07 15:30:21,994 - DEBUG - utilities - Step (163) Logs: {'loss': 3.1125, 'grad_norm': 40.326377868652344, 'learning_rate': 5.577889447236181e-05, 'epoch': 0.52, 'iter_time': 0.5858677655090521, 'flops': 3747719095697.6714, 'remaining_time': 21.677107323834925}\n",
      "2024-03-07 15:30:22,517 - DEBUG - utilities - Step (164) Logs: {'loss': 2.114, 'grad_norm': 25.259187698364258, 'learning_rate': 5.42713567839196e-05, 'epoch': 0.52, 'iter_time': 0.5854786685639364, 'flops': 3750209751855.759, 'remaining_time': 21.07723206830171}\n",
      "2024-03-07 15:30:23,122 - DEBUG - utilities - Step (165) Logs: {'loss': 3.1264, 'grad_norm': 33.79737091064453, 'learning_rate': 5.276381909547739e-05, 'epoch': 0.52, 'iter_time': 0.5855991273391538, 'flops': 3749438327083.3735, 'remaining_time': 20.49596945687038}\n",
      "2024-03-07 15:30:23,714 - DEBUG - utilities - Step (166) Logs: {'loss': 3.5992, 'grad_norm': 34.53175735473633, 'learning_rate': 5.125628140703517e-05, 'epoch': 0.53, 'iter_time': 0.5856383150274104, 'flops': 3749187435335.8066, 'remaining_time': 19.91170271093195}\n",
      "2024-03-07 15:30:24,251 - DEBUG - utilities - Step (167) Logs: {'loss': 3.2386, 'grad_norm': 51.5418815612793, 'learning_rate': 4.974874371859296e-05, 'epoch': 0.53, 'iter_time': 0.5853432517453848, 'flops': 3751077347872.2554, 'remaining_time': 19.3163273075977}\n",
      "2024-03-07 15:30:24,804 - DEBUG - utilities - Step (168) Logs: {'loss': 3.5146, 'grad_norm': 36.97066879272461, 'learning_rate': 4.824120603015075e-05, 'epoch': 0.53, 'iter_time': 0.5851515981251608, 'flops': 3752305931295.3604, 'remaining_time': 18.724851140005146}\n",
      "2024-03-07 15:30:25,338 - DEBUG - utilities - Step (169) Logs: {'loss': 3.0381, 'grad_norm': 33.60532760620117, 'learning_rate': 4.673366834170854e-05, 'epoch': 0.54, 'iter_time': 0.5848433205059597, 'flops': 3754283814770.2256, 'remaining_time': 18.13014293568475}\n",
      "2024-03-07 15:30:25,857 - DEBUG - utilities - Step (170) Logs: {'loss': 3.8236, 'grad_norm': 55.02488708496094, 'learning_rate': 4.5226130653266326e-05, 'epoch': 0.54, 'iter_time': 0.5844582185237366, 'flops': 3756757528190.7466, 'remaining_time': 17.5337465557121}\n",
      "2024-03-07 15:30:26,448 - DEBUG - utilities - Step (171) Logs: {'loss': 3.4248, 'grad_norm': 37.74738311767578, 'learning_rate': 4.371859296482412e-05, 'epoch': 0.54, 'iter_time': 0.5844961460898904, 'flops': 3756513754693.4746, 'remaining_time': 16.950388236606823}\n",
      "2024-03-07 15:30:26,992 - DEBUG - utilities - Step (172) Logs: {'loss': 4.4414, 'grad_norm': 39.32648468017578, 'learning_rate': 4.221105527638191e-05, 'epoch': 0.55, 'iter_time': 0.5842567494041041, 'flops': 3758052970019.445, 'remaining_time': 16.359188983314915}\n",
      "2024-03-07 15:30:27,574 - DEBUG - utilities - Step (173) Logs: {'loss': 3.0793, 'grad_norm': 40.17476272583008, 'learning_rate': 4.07035175879397e-05, 'epoch': 0.55, 'iter_time': 0.5842428955920907, 'flops': 3758142082544.006, 'remaining_time': 15.77455818098645}\n",
      "2024-03-07 15:30:28,125 - DEBUG - utilities - Step (174) Logs: {'loss': 5.9916, 'grad_norm': 55.46894454956055, 'learning_rate': 3.919597989949749e-05, 'epoch': 0.55, 'iter_time': 0.5840525833857542, 'flops': 3759366664596.719, 'remaining_time': 15.185367168029607}\n",
      "2024-03-07 15:30:28,700 - DEBUG - utilities - Step (175) Logs: {'loss': 3.5646, 'grad_norm': 38.031005859375, 'learning_rate': 3.768844221105527e-05, 'epoch': 0.56, 'iter_time': 0.5839999256462887, 'flops': 3759705636815.184, 'remaining_time': 14.599998141157217}\n",
      "2024-03-07 15:30:29,223 - DEBUG - utilities - Step (176) Logs: {'loss': 2.2425, 'grad_norm': 35.998046875, 'learning_rate': 3.618090452261306e-05, 'epoch': 0.56, 'iter_time': 0.5836532974243164, 'flops': 3761938503631.4595, 'remaining_time': 14.007679138183594}\n",
      "2024-03-07 15:30:29,805 - DEBUG - utilities - Step (177) Logs: {'loss': 2.8993, 'grad_norm': 30.33537483215332, 'learning_rate': 3.467336683417085e-05, 'epoch': 0.56, 'iter_time': 0.5836402435194362, 'flops': 3762022644483.5283, 'remaining_time': 13.423725600947034}\n",
      "2024-03-07 15:30:30,386 - DEBUG - utilities - Step (178) Logs: {'loss': 4.3766, 'grad_norm': 42.47184371948242, 'learning_rate': 3.3165829145728643e-05, 'epoch': 0.57, 'iter_time': 0.5836278705273644, 'flops': 3762102399887.108, 'remaining_time': 12.839813151602018}\n",
      "2024-03-07 15:30:31,001 - DEBUG - utilities - Step (179) Logs: {'loss': 3.5752, 'grad_norm': 27.42333221435547, 'learning_rate': 3.165829145728643e-05, 'epoch': 0.57, 'iter_time': 0.5838040046477586, 'flops': 3760967370679.083, 'remaining_time': 12.259884097602932}\n",
      "2024-03-07 15:30:31,562 - DEBUG - utilities - Step (180) Logs: {'loss': 3.1767, 'grad_norm': 34.11717987060547, 'learning_rate': 3.015075376884422e-05, 'epoch': 0.57, 'iter_time': 0.5836756815457477, 'flops': 3761794232264.766, 'remaining_time': 11.673513630914954}\n",
      "2024-03-07 15:30:32,095 - DEBUG - utilities - Step (181) Logs: {'loss': 4.6249, 'grad_norm': 44.65822219848633, 'learning_rate': 2.8643216080402008e-05, 'epoch': 0.57, 'iter_time': 0.5833973103099399, 'flops': 3763589193075.8364, 'remaining_time': 11.084548895888858}\n",
      "2024-03-07 15:30:32,628 - DEBUG - utilities - Step (182) Logs: {'loss': 3.5522, 'grad_norm': 35.86865234375, 'learning_rate': 2.71356783919598e-05, 'epoch': 0.58, 'iter_time': 0.5831166183092318, 'flops': 3765400853637.854, 'remaining_time': 10.496099129566172}\n",
      "2024-03-07 15:30:33,199 - DEBUG - utilities - Step (183) Logs: {'loss': 3.2632, 'grad_norm': 28.67902183532715, 'learning_rate': 2.5628140703517586e-05, 'epoch': 0.58, 'iter_time': 0.5830485991069249, 'flops': 3765840130162.697, 'remaining_time': 9.911826184817723}\n",
      "2024-03-07 15:30:33,707 - DEBUG - utilities - Step (184) Logs: {'loss': 1.3854, 'grad_norm': 29.31052017211914, 'learning_rate': 2.4120603015075376e-05, 'epoch': 0.58, 'iter_time': 0.5826414869131287, 'flops': 3768471455722.775, 'remaining_time': 9.322263790610059}\n",
      "2024-03-07 15:30:34,290 - DEBUG - utilities - Step (185) Logs: {'loss': 2.8351, 'grad_norm': 32.04682540893555, 'learning_rate': 2.2613065326633163e-05, 'epoch': 0.59, 'iter_time': 0.5826419773309127, 'flops': 3768468283748.402, 'remaining_time': 8.739629659963692}\n",
      "2024-03-07 15:30:34,851 - DEBUG - utilities - Step (186) Logs: {'loss': 2.344, 'grad_norm': 37.40082550048828, 'learning_rate': 2.1105527638190954e-05, 'epoch': 0.59, 'iter_time': 0.5825268101047825, 'flops': 3769213320768.966, 'remaining_time': 8.155375341466954}\n",
      "2024-03-07 15:30:35,379 - DEBUG - utilities - Step (187) Logs: {'loss': 2.686, 'grad_norm': 48.63970184326172, 'learning_rate': 1.9597989949748744e-05, 'epoch': 0.59, 'iter_time': 0.5822332905184838, 'flops': 3771113483388.6577, 'remaining_time': 7.56903277674029}\n",
      "2024-03-07 15:30:35,959 - DEBUG - utilities - Step (188) Logs: {'loss': 2.1422, 'grad_norm': 42.013633728027344, 'learning_rate': 1.809045226130653e-05, 'epoch': 0.6, 'iter_time': 0.5822176958787888, 'flops': 3771214492266.3315, 'remaining_time': 6.986612350545466}\n",
      "2024-03-07 15:30:36,481 - DEBUG - utilities - Step (189) Logs: {'loss': 1.9405, 'grad_norm': 28.77492332458496, 'learning_rate': 1.6582914572864322e-05, 'epoch': 0.6, 'iter_time': 0.5819020106437358, 'flops': 3773260398126.1675, 'remaining_time': 6.400922117081094}\n",
      "2024-03-07 15:30:37,043 - DEBUG - utilities - Step (190) Logs: {'loss': 3.4927, 'grad_norm': 40.7259635925293, 'learning_rate': 1.507537688442211e-05, 'epoch': 0.6, 'iter_time': 0.5817933107810046, 'flops': 3773965378537.123, 'remaining_time': 5.817933107810046}\n",
      "2024-03-07 15:30:37,654 - DEBUG - utilities - Step (191) Logs: {'loss': 3.3056, 'grad_norm': 47.88717269897461, 'learning_rate': 1.35678391959799e-05, 'epoch': 0.61, 'iter_time': 0.5819505566044858, 'flops': 3772945635043.448, 'remaining_time': 5.2375550094403724}\n",
      "2024-03-07 15:30:38,201 - DEBUG - utilities - Step (192) Logs: {'loss': 2.9116, 'grad_norm': 26.18974494934082, 'learning_rate': 1.2060301507537688e-05, 'epoch': 0.61, 'iter_time': 0.581767078469561, 'flops': 3774135549450.6226, 'remaining_time': 4.654136627756488}\n",
      "2024-03-07 15:30:38,800 - DEBUG - utilities - Step (193) Logs: {'loss': 2.3821, 'grad_norm': 25.755640029907227, 'learning_rate': 1.0552763819095477e-05, 'epoch': 0.61, 'iter_time': 0.5818545718987783, 'flops': 3773568032965.404, 'remaining_time': 4.0729820032914485}\n",
      "2024-03-07 15:30:39,349 - DEBUG - utilities - Step (194) Logs: {'loss': 2.5098, 'grad_norm': 33.4577522277832, 'learning_rate': 9.045226130653266e-06, 'epoch': 0.62, 'iter_time': 0.5816848858650484, 'flops': 3774668838243.4565, 'remaining_time': 3.49010931519029}\n",
      "2024-03-07 15:30:39,876 - DEBUG - utilities - Step (195) Logs: {'loss': 2.8094, 'grad_norm': 68.23987579345703, 'learning_rate': 7.537688442211055e-06, 'epoch': 0.62, 'iter_time': 0.5814018446145598, 'flops': 3776506443332.008, 'remaining_time': 2.907009223072799}\n",
      "2024-03-07 15:30:40,417 - DEBUG - utilities - Step (196) Logs: {'loss': 2.0543, 'grad_norm': 29.96698570251465, 'learning_rate': 6.030150753768844e-06, 'epoch': 0.62, 'iter_time': 0.581193932508811, 'flops': 3777857423380.299, 'remaining_time': 2.324775730035244}\n",
      "2024-03-07 15:30:40,941 - DEBUG - utilities - Step (197) Logs: {'loss': 2.121, 'grad_norm': 21.304256439208984, 'learning_rate': 4.522613065326633e-06, 'epoch': 0.63, 'iter_time': 0.5809039278906218, 'flops': 3779743442818.347, 'remaining_time': 1.7427117836718655}\n",
      "2024-03-07 15:30:41,510 - DEBUG - utilities - Step (198) Logs: {'loss': 2.1506, 'grad_norm': 23.58435821533203, 'learning_rate': 3.015075376884422e-06, 'epoch': 0.63, 'iter_time': 0.5808424465547358, 'flops': 3780143523214.588, 'remaining_time': 1.1616848931094717}\n",
      "2024-03-07 15:30:42,064 - DEBUG - utilities - Step (199) Logs: {'loss': 4.0178, 'grad_norm': 29.589813232421875, 'learning_rate': 1.507537688442211e-06, 'epoch': 0.63, 'iter_time': 0.580707458534626, 'flops': 3781022234315.04, 'remaining_time': 0.580707458534626}\n",
      "2024-03-07 15:30:42,619 - DEBUG - utilities - Step (200) Logs: {'loss': 2.2976, 'grad_norm': 25.23436737060547, 'learning_rate': 0.0, 'epoch': 0.63, 'iter_time': 0.5805771554534759, 'flops': 3781870836163.047, 'remaining_time': 0.0}\n",
      "2024-03-07 15:30:43,224 - DEBUG - utilities - Step (200) Logs: {'train_runtime': 116.9844, 'train_samples_per_second': 6.839, 'train_steps_per_second': 1.71, 'total_flos': 17142397698048.0, 'train_loss': 4.921914138793945, 'epoch': 0.63, 'iter_time': 0.5836181305161673, 'flops': 3762165185667.0273, 'remaining_time': 0.0}\n"
     ]
    }
   ],
   "source": [
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: lamini_docs_200_steps/final_3\n"
     ]
    }
   ],
   "source": [
    "save_dir = f'{output_dir}/final_3'\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "print(\"Saved model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = f'{output_dir}/final_2'\n",
    "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(dir, local_files_only=True)\n",
    "finetuned_slightly_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_slightly_model.to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): Can Lamini generate technical documentation or user manuals for software projects?\n",
      "Finetuned slightly model's answer: \n",
      "Yes, Lamini can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate technical documentation or user manuals for software projects. It can generate\n"
     ]
    }
   ],
   "source": [
    "test_question = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_question)\n",
    "\n",
    "print(\"Finetuned slightly model's answer: \")\n",
    "print(inference(test_question, finetuned_slightly_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target answer output (test): Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.\n"
     ]
    }
   ],
   "source": [
    "test_answer = test_dataset[0]['answer']\n",
    "print(\"Target answer output (test):\", test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_longer_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lamini/lamini_docs_finetuned\")\n",
    "\n",
    "finetuned_longer_model.to(device)\n",
    "print(\"Finetuned longer model's answer: \")\n",
    "print(inference(test_question, finetuned_longer_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_finetuned_model = BasicModelRunner(model_name_to_id[\"bigger_model_name\"])\n",
    "bigger_finetuned_output = bigger_finetuned_model(test_question)\n",
    "print(\"Bigger (2.8B) finetuned model (test): \", bigger_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(train_dataset)):\n",
    " if \"keep the discussion relevant to Lamini\" in train_dataset[i][\"answer\"]:\n",
    "  print(i, train_dataset[i][\"question\"], train_dataset[i][\"answer\"])\n",
    "  count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "print(inference(\"What do you think of Mars?\", base_model, base_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference(\"What do you think of Mars?\", finetuned_longer_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModelRunner(\"EleutherAI/pythia-410m\") \n",
    "model.load_data_from_jsonlines(\"lamini_docs.jsonl\", input_key=\"question\", output_key=\"answer\")\n",
    "model.train(is_public=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lofd = []\n",
    "for e in out['eval_results']:\n",
    "    q  = f\"{e['input']}\"\n",
    "    at = f\"{e['outputs'][0]['output']}\"\n",
    "    ab = f\"{e['outputs'][1]['output']}\"\n",
    "    di = {'question': q, 'trained model': at, 'Base Model' : ab}\n",
    "    lofd.append(di)\n",
    "df = pd.DataFrame.from_dict(lofd)\n",
    "style_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "style_df = style_df.set_properties(**{\"vertical-align\": \"text-top\"})\n",
    "style_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-ai",
   "language": "python",
   "name": "deep-learn-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
